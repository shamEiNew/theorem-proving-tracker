<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Neuro-Symbolic AI + Lean Roadmap (Mathematician's Track)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
    :root {
      --bg: #ffffff;
      --fg: #000000;
      --border: #d0d0d0;
      --header-bg: #000000;
      --header-fg: #ffffff;
      --accent: #111111;
      --critical: #c41e3a;
    }

    * {
      box-sizing: border-box;
    }

    body {
      margin: 0;
      padding: 0;
      background: var(--bg);
      color: var(--fg);
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
      line-height: 1.5;
    }

    .wrapper {
      max-width: 1400px;
      margin: 0 auto;
      padding: 24px 16px 48px;
    }

    h1 {
      font-size: 1.8rem;
      margin: 0 0 0.25rem;
      font-weight: 600;
    }

    h2 {
      font-size: 1.1rem;
      font-weight: 500;
      margin: 1.5rem 0 0.5rem;
      color: var(--accent);
    }

    .subtitle {
      font-size: 0.95rem;
      color: #555;
      margin-bottom: 1rem;
    }

    .meta {
      font-size: 0.8rem;
      color: #777;
      margin-bottom: 1.25rem;
    }

    .legend {
      font-size: 0.8rem;
      color: #555;
      margin-bottom: 0.75rem;
    }

    .legend span {
      display: inline-block;
      margin-right: 12px;
    }

    .critical-note {
      background: #fff3cd;
      border-left: 4px solid var(--critical);
      padding: 12px;
      margin: 1rem 0;
      font-size: 0.9rem;
    }

    .week0-box {
      background: #e8f4f8;
      border: 2px solid #0066cc;
      padding: 16px;
      margin: 1.5rem 0;
      border-radius: 4px;
    }

    .week0-box h3 {
      margin-top: 0;
      color: #0066cc;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      table-layout: fixed;
      border: 1px solid var(--border);
      font-size: 0.85rem;
    }

    thead {
      background: var(--header-bg);
      color: var(--header-fg);
    }

    th, td {
      border: 1px solid var(--border);
      padding: 8px 6px;
      vertical-align: top;
      word-wrap: break-word;
      white-space: normal;
    }

    th {
      text-align: left;
      font-weight: 500;
    }

    tr:nth-child(even) td {
      background: #fafafa;
    }

    tr:nth-child(odd) td {
      background: #ffffff;
    }

    .critical-week {
      background: #fff9e6 !important;
      border-left: 3px solid var(--critical);
    }

    .new-week {
      background: #f0f8ff !important;
      border-left: 3px solid #0066cc;
    }

    .col-week {
      width: 50px;
    }

    .col-stage {
      width: 120px;
    }

    .col-hours {
      width: 60px;
      text-align: center;
    }

    .col-completed {
      width: 70px;
      text-align: center;
    }

    .col-remarks {
      width: 140px;
    }

    input[type="checkbox"] {
      width: 16px;
      height: 16px;
      cursor: pointer;
    }

    .small-note {
      font-size: 0.8rem;
      color: #777;
      margin-top: 1rem;
    }

    .emphasis {
      color: var(--critical);
      font-weight: 600;
    }

    @media (max-width: 768px) {
      table {
        font-size: 0.8rem;
      }
      h1 {
        font-size: 1.4rem;
      }
    }
  </style>
</head>
<body>
  <div class="wrapper">
    <h1>Neuro-Symbolic AI + Lean Roadmap (Mathematician's Track — Enhanced)</h1>
    <div class="subtitle">
      18-week accelerated plan: Leveraging mathematical maturity and Python skills to build AI tools for Theorem Proving.
    </div>
    <div class="meta">
      Phases: P0 Setup · P1 Lean Foundations · P2 The Python-Lean Bridge · P3 Deep Learning & RAG · P4 Research & Portfolio.
    </div>

    <div class="legend">
      <span><strong>Hours/week:</strong> suggested 10–12 hours</span>
      <span><strong>Goal:</strong> Build an AI-assisted proving tool with quantitative benchmarks</span>
      <span><strong>Focus:</strong> Metaprogramming, RAG Architecture & Evaluation Rigor</span>
    </div>

    <div class="critical-note">
      <strong>⚠️ Critical Success Factor:</strong> Week 4 (Metaprogramming) is where 50% of learners quit. If stuck, extend to 2 weeks and ask for help on Lean Zulip. <span class="emphasis">Do not skip this week</span>—it's the difference between being a "Lean user" and a "Lean builder."
    </div>

    <div class="week0-box">
      <h3>Week 0: Environment Setup (Complete Before Week 1)</h3>
      <ul>
        <li><strong>Day 1:</strong> Install Lean 4 (latest stable) + VS Code with Lean extension</li>
        <li><strong>Day 2:</strong> Clone Mathlib and build it (2-4 hours compile time—run overnight)</li>
        <li><strong>Day 3:</strong> Test LeanDojo installation: <code>pip install lean-dojo</code> and verify with a simple trace</li>
        <li><strong>Day 4:</strong> Baseline Assessment: Complete first 10 levels of Natural Number Game</li>
        <li><strong>Day 5:</strong> Join Lean Zulip (#new-members, #machine-learning) and introduce yourself</li>
      </ul>
      <p style="margin-bottom: 0;"><strong>Success Metric:</strong> You can compile a "Hello World" Lean file and run LeanDojo's basic example.</p>
    </div>

    <h2>Week-by-Week Plan (with Deliverables & Enhancements)</h2>

    <table>
      <thead>
        <tr>
          <th class="col-week">Week</th>
          <th class="col-stage">Phase</th>
          <th>Primary Focus</th>
          <th>Goals for the Week</th>
          <th>Deliverable (GitHub / Notebooks)</th>
          <th>Core References / Resources</th>
          <th class="col-hours">Hours</th>
          <th class="col-completed">Done</th>
          <th class="col-remarks">Remarks</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>1</td>
          <td>P1 — Foundation</td>
          <td>Quantifiers as Functions</td>
          <td>
            Finish TPiL4 Chapter 4 (Quantifiers). <br>
            Internalize the Curry-Howard correspondence (Proofs = Programs). <br>
            <strong>Key concept:</strong> `∀` is a Pi-type (dependent function).
          </td>
          <td>
            <em>week1-quantifiers.lean</em>: Manually implement `and_comm` and `quantifier_swap` without tactics.
          </td>
          <td>
            - TPiL4 (Ch 4)<br>
            - "Propositions as Types" (Wadler)
          </td>
          <td class="col-hours">8–10</td>
          <td class="col-completed"><input type="checkbox" checked></td>
          <td>Critical for AI intuition.</td>
        </tr>

        <tr>
          <td>2</td>
          <td>P1 — Foundation</td>
          <td>Tactics & Induction</td>
          <td>
            Master `induction`, `rewrite`, and `simp`. <br>
            Complete the Natural Number Game (NNG) to build "tactic intuition" (needed for generating data later).
          </td>
          <td>
            Screenshot of NNG Certificate + <em>week2-tactics.lean</em> with commented tactic states.
          </td>
          <td>
            - TPiL4 (Ch 5-8)<br>
            - Natural Number Game (Lean 4)
          </td>
          <td class="col-hours">8–10</td>
          <td class="col-completed"><input type="checkbox"></td>
          <td>Gamified learning.</td>
        </tr>

        <tr>
          <td>3</td>
          <td>P1 — Foundation</td>
          <td>Mathlib & Real Math</td>
          <td>
            Switch to <em>Mathematics in Lean</em> (MIL). <br>
            Learn how Algebra and Topology are encoded. <br>
            Understand `Type`, `Type u`, and Universe Polymorphism.
          </td>
          <td>
            <em>week3-algebra.lean</em>: Solve 5 exercises from MIL "Algebra" chapter.
          </td>
          <td>
            - Mathematics in Lean<br>
            - Mathlib documentation
          </td>
          <td class="col-hours">8–10</td>
          <td class="col-completed"><input type="checkbox"></td>
          <td>Start exploring the API.</td>
        </tr>

        <tr class="critical-week">
          <td>4</td>
          <td>P1 — Foundation</td>
          <td>Lean 4 Metaprogramming</td>
          <td>
            <strong class="emphasis">The Pivot:</strong> Stop proving; start hacking. <br>
            Learn `Lean.Expr` (Expression tree). <br>
            Write a tactic that inspects the goal state.
          </td>
          <td>
            <em>week4-meta.lean</em>: A tactic `elab "check_type"` that prints the current goal's type to the console.
          </td>
          <td>
            - Lean 4 Metaprogramming Book<br>
            - "Macro" vs "Elab" chapters
          </td>
          <td class="col-hours">10–12</td>
          <td class="col-completed"><input type="checkbox"></td>
          <td class="emphasis">Hardest week. Extend if needed.</td>
        </tr>

        <tr class="new-week">
          <td>4.5</td>
          <td>P1 — Foundation</td>
          <td>Proof State Serialization</td>
          <td>
            <strong>CRITICAL GAP:</strong> Bridge Lean expressions to ML format. <br>
            Convert `Lean.Expr` to JSON/S-expressions. <br>
            This is the bottleneck for Python integration.
          </td>
          <td>
            <em>state_to_json.lean</em>: Function that exports goal states as JSON with hypotheses, goal type, and metavariables.
          </td>
          <td>
            - Lean 4 Metaprogramming (Ch. IO)<br>
            - LeanDojo source code (state extraction)
          </td>
          <td class="col-hours">8–10</td>
          <td class="col-completed"><input type="checkbox"></td>
          <td>NEW: Enables ML pipeline.</td>
        </tr>

        <tr>
          <td>5</td>
          <td>P2 — The Bridge</td>
          <td>"Hello World" Python-Lean</td>
          <td>
            Install `lean-interact` or `repl`. <br>
            Write a Python script that starts a Lean server and sends a command string.
          </td>
          <td>
            <em>bridge.py</em>: Script that sends "1+1" to Lean and parses the output "2".
          </td>
          <td>
            - lean-interact (PyPI)<br>
            - Lean REPL documentation
          </td>
          <td class="col-hours">6–8</td>
          <td class="col-completed"><input type="checkbox"></td>
          <td>Proof of concept.</td>
        </tr>

        <tr>
          <td>6</td>
          <td>P2 — The Bridge</td>
          <td>LeanDojo (Industrial Tooling)</td>
          <td>
            Install <strong>LeanDojo</strong>. <br>
            Use it to trace a repo and extract (Theorem, Proof) pairs. <br>
            <strong>NEW:</strong> Understand the tactic state <em>graph structure</em> (critical for Week 12 search).
          </td>
          <td>
            <em>extract_data.py</em>: Generates a JSON file with 100 theorems and their tactic steps from Mathlib. Include visualization of a proof state graph.
          </td>
          <td>
            - LeanDojo Paper<br>
            - LeanDojo GitHub / Docs<br>
            - NetworkX (for graph viz)
          </td>
          <td class="col-hours">8–10</td>
          <td class="col-completed"><input type="checkbox"></td>
          <td>ENHANCED: Add graph understanding.</td>
        </tr>

        <tr>
          <td>7</td>
          <td>P2 — The Bridge</td>
          <td>Premise Selection (Data Eng)</td>
          <td>
            <strong>Problem:</strong> Which lemma to use? <br>
            Build a "Semantic Search" tool. <br>
            Use TF-IDF or OpenAI Embeddings on theorem statements.
          </td>
          <td>
            <em>retrieve_lemma.py</em>: Input a theorem string, output top-5 relevant Mathlib lemma names.
          </td>
          <td>
            - "HyperTree Proof Search"<br>
            - scikit-learn (TF-IDF)<br>
            - FAISS (Facebook AI Similarity Search)
          </td>
          <td class="col-hours">8–10</td>
          <td class="col-completed"><input type="checkbox"></td>
          <td>Critical for RAG.</td>
        </tr>

        <tr>
          <td>8</td>
          <td>P2 — The Bridge</td>
          <td>The Gym (Eval Loop)</td>
          <td>
            Create the "Agent Loop": <br>
            1. Python reads state. <br>
            2. Python proposes tactic (random for now). <br>
            3. Lean executes. <br>
            4. Python gets feedback.
          </td>
          <td>
            <em>agent_loop.py</em>: A script that tries `simp`, `ring`, `linarith` on a goal until one works.
          </td>
          <td>
            - OpenAI Gym interface concepts<br>
            - LeanDojo `Dojo` class
          </td>
          <td class="col-hours">8–10</td>
          <td class="col-completed"><input type="checkbox"></td>
          <td>Foundation for RL.</td>
        </tr>

        <tr>
          <td>9</td>
          <td>P3 — Neuro Layer</td>
          <td>Deep Learning Fast Track</td>
          <td>
            Learn Seq2Seq architectures. <br>
            Understand "Attention" mechanisms (Transformers). <br>
            Map "English->French" to "Theorem->Proof".
          </td>
          <td>
            <em>seq2seq_tutorial.ipynb</em>: Complete the PyTorch Translation tutorial.
          </td>
          <td>
            - PyTorch Seq2Seq Tutorial<br>
            - "The Illustrated Transformer"
          </td>
          <td class="col-hours">10–12</td>
          <td class="col-completed"><input type="checkbox"></td>
          <td>Theory week.</td>
        </tr>

        <tr class="new-week">
          <td>9.5</td>
          <td>P3 — Neuro Layer</td>
          <td>Benchmark Familiarity</td>
          <td>
            <strong>NEW:</strong> Understand what "good" looks like. <br>
            Run evaluation on MiniF2F or ProofNet using existing pretrained models. <br>
            Learn metrics: pass@1, pass@64, proof success rate.
          </td>
          <td>
            <em>baseline_eval.ipynb</em>: Report showing baseline model performance on 50 test problems. Document failure modes.
          </td>
          <td>
            - MiniF2F benchmark<br>
            - ProofNet<br>
            - LeanDojo pretrained models
          </td>
          <td class="col-hours">6–8</td>
          <td class="col-completed"><input type="checkbox"></td>
          <td>NEW: Prevents reinventing solved problems.</td>
        </tr>

        <tr>
          <td>10</td>
          <td>P3 — Neuro Layer</td>
          <td>LLM Fine-Tuning</td>
          <td>
            Use HuggingFace `transformers`. <br>
            <strong>NEW:</strong> Fine-tune using LoRA/QLoRA (more practical than full fine-tuning). <br>
            Task: Input State -> Output Tactic. <br>
            <strong>NEW:</strong> Test on validation set from <em>different</em> Mathlib domain.
          </td>
          <td>
            <em>train_prover.py</em> + Training Loss Curve + Cross-domain validation results.
          </td>
          <td>
            - HuggingFace Trainer API<br>
            - PEFT library (LoRA)<br>
            - LeanDojo Benchmark datasets
          </td>
          <td class="col-hours">10–12</td>
          <td class="col-completed"><input type="checkbox"></td>
          <td>ENHANCED: Add generalization test.</td>
        </tr>

        <tr>
          <td>11</td>
          <td>P3 — Neuro Layer</td>
          <td>Retrieval Augmented Generation (RAG)</td>
          <td>
            Connect Week 7 (Retriever) with Week 10 (Generator). <br>
            Prompt: "Given these lemmas [L1, L2], prove [Goal]". <br>
            <strong>NEW:</strong> Address cold-start: Try few-shot prompting with GPT-4 for domains with little training data.
          </td>
          <td>
            <em>rag_prover.py</em>: A script that retrieves premises before generating a tactic. Include few-shot GPT-4 comparison.
          </td>
          <td>
            - "LeanDojo: RAG for Theorems"<br>
            - FAISS<br>
            - OpenAI API (few-shot)
          </td>
          <td class="col-hours">8–10</td>
          <td class="col-completed"><input type="checkbox"></td>
          <td>ENHANCED: Add data efficiency experiments.</td>
        </tr>

        <tr>
          <td>12</td>
          <td>P3 — Neuro Layer</td>
          <td>Tree Search (Inference)</td>
          <td>
            LLMs make mistakes. Implement Search. <br>
            Use Best-First Search (BFS) where the LLM "scores" the branches.
          </td>
          <td>
            <em>proof_search.py</em>: Implements a search tree allowing backtracking when tactics fail.
          </td>
          <td>
            - "AlphaProof" concepts<br>
            - Graph Theory (Trees)<br>
            - Week 6 state graph understanding
          </td>
          <td class="col-hours">10–12</td>
          <td class="col-completed"><input type="checkbox"></td>
          <td>The "Brain" of the agent.</td>
        </tr>

        <tr>
          <td>13</td>
          <td>P4 — Portfolio</td>
          <td>Community & Landscape</td>
          <td>
            Read recent AITP papers (2024-2025). <br>
            <strong>Priority:</strong> Draft, Sketch, and Prove (2022), LeanDojo (2023), AlphaProof (2024), Baldur (2024). <br>
            Join Lean Zulip `#machine-learning`. <br>
            Identify a gap (e.g., "AI is bad at inequality proofs").
          </td>
          <td>
            <em>lit_review.md</em>: Summary of 3 top papers and where your tool fits in the landscape.
          </td>
          <td>
            - AITP Conference Proceedings<br>
            - arXiv (Neuro-symbolic AI)<br>
            - Papers: Draft-Sketch-Prove, LeanDojo, AlphaProof, Baldur
          </td>
          <td class="col-hours">6–8</td>
          <td class="col-completed"><input type="checkbox"></td>
          <td>ENHANCED: Specific paper list.</td>
        </tr>

        <tr>
          <td>14</td>
          <td>P4 — Portfolio</td>
          <td>Capstone: "Auto-Formalizer" or "Copilot"</td>
          <td>
            Build a user-facing tool. <br>
            Example: A CLI tool where you type a math problem, and it suggests the Lean code. <br>
            <strong>NEW:</strong> Add human-in-the-loop: suggest 3 tactics, let user pick, learn from choice. <br>
            <strong>NEW:</strong> Add quantitative benchmark: "My tool solves X% of MiniF2F."
          </td>
          <td>
            <em>MVP v0.1</em>: Working end-to-end pipeline on unseen problems + benchmark results (e.g., "15% of MiniF2F-test solved").
          </td>
          <td>
            - Your codebase (Weeks 5-12)<br>
            - VS Code Extension API (optional)<br>
            - MiniF2F test set
          </td>
          <td class="col-hours">12–15</td>
          <td class="col-completed"><input type="checkbox"></td>
          <td>ENHANCED: Add metrics & interactivity.</td>
        </tr>

        <tr>
          <td>15</td>
          <td>P4 — Portfolio</td>
          <td>Polish & Documentation</td>
          <td>
            Clean up code. Add docstrings. <br>
            Write a technical blog post: "How I taught an AI to prove Math using LeanDojo." <br>
            <strong>Include concrete numbers:</strong> "Solved 15/100 MiniF2F problems (15% pass@1)."
          </td>
          <td>
            Public GitHub Repo with nice README + Medium/Substack post with quantitative results.
          </td>
          <td>
            - "Write the Docs" guide<br>
            - Distill.pub style
          </td>
          <td class="col-hours">8–10</td>
          <td class="col-completed"><input type="checkbox"></td>
          <td>ENHANCED: Emphasize metrics.</td>
        </tr>

        <tr>
          <td>16</td>
          <td>P4 — Portfolio</td>
          <td>Outreach & Application</td>
          <td>
            Update CV: "Neuro-Symbolic AI Engineer". <br>
            Email labs/startups with your Blog Post + Repo. <br>
            Target: Symbolica, DeepMind, OpenAI (reasoning teams), Anthropic.
          </td>
          <td>
            <em>applications.md</em>: List of 5 labs/companies contacted with personalized emails.
          </td>
          <td>
            - "Cold Emailing for Research"<br>
            - LinkedIn
          </td>
          <td class="col-hours">5–7</td>
          <td class="col-completed"><input type="checkbox"></td>
          <td>Launch.</td>
        </tr>

        <tr class="new-week">
          <td>17</td>
          <td>P4 — Optional</td>
          <td>Neurosymbolic Hybrid</td>
          <td>
            <strong>OPTIONAL:</strong> Combine symbolic methods (SMT solvers, CAS) with neural tactics. <br>
            Pure LLM approaches struggle with arithmetic/algebra. <br>
            Interface Lean with Z3 or Mathematica.
          </td>
          <td>
            <em>hybrid_solver.py</em>: Demo where Z3 handles inequalities and LLM handles high-level proof structure.
          </td>
          <td>
            - Z3 Python API<br>
            - Lean-Z3 integration examples<br>
            - Baldur paper (LLM+Sledgehammer)
          </td>
          <td class="col-hours">10–12</td>
          <td class="col-completed"><input type="checkbox"></td>
          <td>NEW: Advanced extension.</td>
        </tr>

        <tr class="new-week">
          <td>18</td>
          <td>P4 — Optional</td>
          <td>Interpretability</td>
          <td>
            <strong>OPTIONAL:</strong> Analyze <em>why</em> your model suggests certain tactics. <br>
            Explainability is crucial for mathematician trust. <br>
            Visualize attention on proof states.
          </td>
          <td>
            <em>interpret_model.ipynb</em>: Attention visualizations showing which parts of the goal state influenced tactic choice.
          </td>
          <td>
            - BertViz (attention visualization)<br>
            - Captum (PyTorch interpretability)<br>
            - "Attention is Not Explanation" paper
          </td>
          <td class="col-hours">8–10</td>
          <td class="col-completed"><input type="checkbox"></td>
          <td>NEW: Trust & debugging.</td>
        </tr>
      </tbody>
    </table>

    <div class="small-note">
      <strong>Success Metric (Week 16+):</strong> You can write a blog post titled <em>"I built an AI that proved [specific theorem class] in Lean with [X]% success rate"</em> with concrete numbers and working code. This is your calling card for ATP industry roles.
    </div>

    <div class="small-note">
      <strong>Note:</strong> Weeks 17-18 are optional extensions if you have extra time or discover specific interests. The core 16-week plan is sufficient for job applications. Focus on <span class="emphasis">quantitative benchmarks</span> over feature completeness.
    </div>
  </div>
</body>
</html>